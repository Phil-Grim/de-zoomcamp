{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/06 14:06:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B00009', pickup_datetime='2019-10-01 00:23:00', dropOff_datetime='2019-10-01 00:35:00', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00009'),\n",
       " Row(dispatching_base_num='B00013', pickup_datetime='2019-10-01 00:11:29', dropOff_datetime='2019-10-01 00:13:22', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00013'),\n",
       " Row(dispatching_base_num='B00014', pickup_datetime='2019-10-01 00:11:43', dropOff_datetime='2019-10-01 00:37:20', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00014'),\n",
       " Row(dispatching_base_num='B00014', pickup_datetime='2019-10-01 00:56:29', dropOff_datetime='2019-10-01 00:57:47', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00014'),\n",
       " Row(dispatching_base_num='B00014', pickup_datetime='2019-10-01 00:23:09', dropOff_datetime='2019-10-01 00:28:27', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00014')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.repartition(6)\n",
    "df.write.parquet('fhv/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhv/2019/10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropOff_datetime: string (nullable = true)\n",
      " |-- PUlocationID: string (nullable = true)\n",
      " |-- DOlocationID: string (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q3\n",
    "\n",
    "from pyspark.sql.functions import col, to_date, unix_timestamp, max\n",
    "\n",
    "df = df.withColumn(\n",
    "    'pickup_date',\n",
    "    to_date(col('pickup_datetime')))\n",
    "df.filter(df.pickup_date == '2019-10-15').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|max(trip_length)|\n",
      "+----------------+\n",
      "|        631152.5|\n",
      "+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Q4 \n",
    "\n",
    "df = df.withColumn('trip_length',\n",
    "              ((unix_timestamp('dropOff_datetime') - unix_timestamp('pickup_datetime'))/3600\n",
    "              ))\n",
    "df.select(max(df.trip_length)).show()\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Â Q6\n",
    "\n",
    "df_zone_lookup = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup_copy.csv')\n",
    "\n",
    "df_zone_lookup = df_zone_lookup.repartition(6)\n",
    "df_zone_lookup.write.parquet('taxi_zone_lookup/')\n",
    "df_zone_lookup = spark.read.parquet('taxi_zone_lookup/')\n",
    "df_zone_lookup.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+-------------------+----------+-------+------------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|pickup_date|        trip_length|LocationID|Borough|        Zone|service_zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+-------------------+----------+-------+------------+------------+\n",
      "|              B01437|2019-10-18 16:58:08|2019-10-18 17:11:20|         264|         130|   null|                B01437| 2019-10-18|               0.22|       264|Unknown|          NV|         N/A|\n",
      "|              B03048|2019-10-11 09:20:25|2019-10-11 09:37:15|         264|         264|   null|                B03048| 2019-10-11|0.28055555555555556|       264|Unknown|          NV|         N/A|\n",
      "|              B01328|2019-10-08 09:02:00|2019-10-08 09:16:00|          78|         242|   null|                B02534| 2019-10-08|0.23333333333333334|        78|  Bronx|East Tremont|   Boro Zone|\n",
      "|              B00310|2019-10-17 14:52:53|2019-10-17 15:07:03|         264|          60|   null|                B00310| 2019-10-17| 0.2361111111111111|       264|Unknown|          NV|         N/A|\n",
      "|              B01239|2019-10-04 12:15:42|2019-10-04 12:42:54|         264|         247|   null|                B03127| 2019-10-04| 0.4533333333333333|       264|Unknown|          NV|         N/A|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+-------------------+----------+-------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_merged = df.join(df_zone_lookup, df.PUlocationID == df_zone_lookup.LocationID)\n",
    "df_merged.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/USERNAME/spark/spark-3.4.2-bin-hadoop3/python/pyspark/sql/dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_merged.registerTempTable('trips_boroughs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|cnt|                Zone|\n",
      "+---+--------------------+\n",
      "|  1|         Jamaica Bay|\n",
      "|  2|Governor's Island...|\n",
      "|  5| Green-Wood Cemetery|\n",
      "|  8|       Broad Channel|\n",
      "| 14|     Highbridge Park|\n",
      "| 15|        Battery Park|\n",
      "| 23|Saint Michaels Ce...|\n",
      "| 25|Breezy Point/Fort...|\n",
      "| 26|Marine Park/Floyd...|\n",
      "| 29|        Astoria Park|\n",
      "| 39|    Inwood Hill Park|\n",
      "| 47|       Willets Point|\n",
      "| 53|Forest Park/Highl...|\n",
      "| 57|  Brooklyn Navy Yard|\n",
      "| 62|        Crotona Park|\n",
      "| 77|        Country Club|\n",
      "| 89|     Freshkills Park|\n",
      "| 98|       Prospect Park|\n",
      "|105|     Columbia Street|\n",
      "|110|  South Williamsburg|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(*) as cnt,\n",
    "    Zone\n",
    "FROM trips_boroughs \n",
    "GROUP BY Zone\n",
    "ORDER BY cnt ASC\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
